# -*- coding: utf-8 -*-
"""CV-3D project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12Hrvej3VAPzuiYFNwH_i1TaRxY7k10jw
"""

# !pip install open3d

import cv2
import numpy as np
import matplotlib.pyplot as plt
import open3d as o3d

# === Step 0: Load Grayscale Images ===
img1 = cv2.imread('box1-4.jpg', cv2.IMREAD_GRAYSCALE)
img2 = cv2.imread('box1-5.jpg', cv2.IMREAD_GRAYSCALE)
color_img1 = cv2.imread('box1-4.jpg')  # for UI


# === Step 1: Detect and Compute SIFT Keypoints ===
sift = cv2.SIFT_create()
kp1, des1 = sift.detectAndCompute(img1, None)
kp2, des2 = sift.detectAndCompute(img2, None)

# === Step 2: Match Features with Ratio Test ===
bf = cv2.BFMatcher()
matches = bf.knnMatch(des1, des2, k=2)

good_matches = []
pts1 = []
pts2 = []

for m, n in matches:
    if m.distance < 0.75 * n.distance:
        good_matches.append(m)
        pts1.append(kp1[m.queryIdx].pt)
        pts2.append(kp2[m.trainIdx].pt)

pts1 = np.array(pts1)
pts2 = np.array(pts2)

# === Step 3: Define Camera Intrinsics (approximate) ===
focal_length = 1000  # pixels
cx, cy = img1.shape[1] // 2, img1.shape[0] // 2

K = np.array([[focal_length, 0, cx],
              [0, focal_length, cy],
              [0, 0, 1]])

# === Step 4: Compute Essential Matrix ===
E, mask = cv2.findEssentialMat(pts1, pts2, K, method=cv2.RANSAC, threshold=1.0)

# === Step 5: Recover Pose (R, t) ===
_, R, t, mask_pose = cv2.recoverPose(E, pts1, pts2, K)

# === Step 6: Build Projection Matrices ===
P1 = K @ np.hstack((np.eye(3), np.zeros((3, 1))))
P2 = K @ np.hstack((R, t))

# === Step 7: Undistort Points and Triangulate ===
pts1_norm = cv2.undistortPoints(np.expand_dims(pts1, axis=1), K, None)
pts2_norm = cv2.undistortPoints(np.expand_dims(pts2, axis=1), K, None)

points_4d = cv2.triangulatePoints(P1, P2, pts1_norm, pts2_norm)
points_3d = points_4d[:3] / points_4d[3]  # Convert from homogeneous


# === Interactive Clicks in Colab ===
clicked_pts = []

def onclick(event):
    if event.xdata is not None and event.ydata is not None:
        x, y = int(event.xdata), int(event.ydata)
        clicked_pts.append((x, y))
        print(f"Clicked at: ({x}, {y})")

        plt.plot(x, y, 'ro')
        if len(clicked_pts) == 2:
            plt.plot([clicked_pts[0][0], clicked_pts[1][0]],
                     [clicked_pts[0][1], clicked_pts[1][1]], 'b-')
            plt.title("2 Points Selected")
        plt.draw()

        if len(clicked_pts) == 2:
            fig.canvas.mpl_disconnect(cid)

fig, ax = plt.subplots()
ax.imshow(cv2.cvtColor(color_img1, cv2.COLOR_BGR2RGB))
plt.title("Click two corners of a known-length edge")
cid = fig.canvas.mpl_connect('button_press_event', onclick)
plt.show()

# === Match Clicked Points to Keypoints ===
indices = []
for (x, y) in clicked_pts:
    dists = [np.linalg.norm((x - kp[0]) + (y - kp[1])) for kp in pts1]
    idx = np.argmin(dists)
    indices.append(idx)

i, j = indices
print(f"Closest keypoint indices: {i}, {j}")

# === Scale Point Cloud ===
real_distance_cm = 22  # CHANGE THIS to your known box edge in cm
dist_3d = np.linalg.norm(points_3d[:, i] - points_3d[:, j])
scale = real_distance_cm / dist_3d
points_scaled = (points_3d * scale).T  # (N, 3)

# === Step 7: Convert to Open3D Point Cloud ===
pcd = o3d.geometry.PointCloud()
pcd.points = o3d.utility.Vector3dVector(points_scaled)

# === Step 8: Estimate Mesh from Point Cloud ===
pcd.estimate_normals()

# === Step 1: Cluster the point cloud (DBSCAN) ===
labels = np.array(pcd.cluster_dbscan(eps=3.0, min_points=30))
num_clusters = labels.max() + 1
print(f"üîç Found {num_clusters} box clusters.")

total_volume = 0.0

# === Step 2: Loop through clusters and compute box volumes ===
for cluster_id in range(num_clusters):
    cluster_mask = labels == cluster_id
    cluster_points = np.asarray(pcd.points)[cluster_mask]

    if len(cluster_points) < 10:
        continue  # skip small noise

    cluster_pcd = o3d.geometry.PointCloud()
    cluster_pcd.points = o3d.utility.Vector3dVector(cluster_points)

    bbox = cluster_pcd.get_axis_aligned_bounding_box()
    extent = bbox.get_extent()  # [x, y, z]
    volume = extent[0] * extent[1] * extent[2]
    total_volume += volume

    print(f"üì¶ Box {cluster_id}: {extent} cm ‚Üí Volume ‚âà {volume:.2f} cm¬≥")

print(f"\n‚úÖ Total Estimated Structure Volume: {total_volume:.2f} cm¬≥")

# Optional: visualize each box in different color
pcd.colors = o3d.utility.Vector3dVector(plt.cm.tab10(labels / num_clusters)[:, :3])
# o3d.visualization.draw_geometries([pcd])
# mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=8)

# # Optional: Remove low-density areas (noise)
# bbox = pcd.get_axis_aligned_bounding_box()
# mesh_crop = mesh.crop(bbox)

# # === Step 9: Estimate Volume ===
# volume = mesh_crop.get_volume()
# print(f"Estimated Volume: {volume:.2f} cm¬≥")

# # === Step 10: Visualize ===
# o3d.visualization.draw_geometries([mesh_crop])

# import matplotlib.pyplot as plt

# xyz = np.asarray(pcd.points)
# fig = plt.figure(figsize=(6,6))
# ax = fig.add_subplot(111, projection='3d')
# ax.scatter(xyz[:,0], xyz[:,1], xyz[:,2], s=1)
# plt.title("3D Point Cloud (projected)")
# plt.show()

# === Project 3D Boxes back to Image and Visualize ===
img_with_boxes = color_img1.copy()
h, w = img_with_boxes.shape[:2]

for cluster_id in range(num_clusters):
    cluster_mask = labels == cluster_id
    cluster_points = np.asarray(pcd.points)[cluster_mask]

    if len(cluster_points) < 10:
        print(f"‚ùå Cluster {cluster_id} skipped: too small")
        continue

    cluster_pcd = o3d.geometry.PointCloud()
    cluster_pcd.points = o3d.utility.Vector3dVector(cluster_points)

    bbox = cluster_pcd.get_axis_aligned_bounding_box()
    corners_3d = np.asarray(bbox.get_box_points())  # (8, 3)

    # Project to image
    corners_3d_hom = np.hstack((corners_3d, np.ones((8, 1)))).T  # (4, 8)
    corners_2d_hom  = P2 @ corners_3d_hom # (3, 8)

    if np.any(corners_2d_hom[2] <= 0):
        print(f"‚ùå Cluster {cluster_id} skipped: behind camera")
        continue

    corners_2d = (corners_2d_hom[:2] / corners_2d_hom[2]).T
    corners_2d_int = np.round(corners_2d).astype(int)

    if np.any(corners_2d_int[:, 0] < 0) or np.any(corners_2d_int[:, 0] >= w) or \
       np.any(corners_2d_int[:, 1] < 0) or np.any(corners_2d_int[:, 1] >= h):
        print(f"‚ùå Cluster {cluster_id} skipped: out of bounds")
        print(f"2D box points:\n{corners_2d_int}")
        continue

    print(f"‚úÖ Drawing Cluster {cluster_id} ‚Üí corners:\n{corners_2d_int}")

    for i, j in [(0,1), (1,3), (3,2), (2,0), (4,5), (5,7), (7,6), (6,4), (0,4), (1,5), (2,6), (3,7)]:
        pt1 = tuple(corners_2d_int[i])
        pt2 = tuple(corners_2d_int[j])
        cv2.line(img_with_boxes, pt1, pt2, (255, 0, 0), 3)

    center = tuple(np.mean(corners_2d_int, axis=0).astype(int))
    cv2.putText(img_with_boxes, f"{cluster_id}", center, cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 4)

# Show result
plt.figure(figsize=(10,10))
plt.imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))
plt.title("Detected Boxes Projected onto Original Image")
plt.axis('off')
plt.show()
